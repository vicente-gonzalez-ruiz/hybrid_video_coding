<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head> <title>Hybrid Video Coding</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='index.css' rel='stylesheet' type='text/css' /> 
<meta content='index.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class='titleHead'>Hybrid Video Coding</h2>
 <div class='author'><span class='ecrm-1200'>Vicente González Ruiz</span></div><br />
<div class='date'><span class='ecrm-1200'>January 12, 2023</span></div>
   </div>
   <h3 class='likesectionHead' id='contents'><a id='x1-1000'></a>Contents</h3>
   <div class='tableofcontents'>
    <span class='sectionToc'>1 <a href='#hybrid-video-coding' id='QQ2-1-2'>Hybrid video coding</a></span>
<br />     <span class='subsectionToc'>1.1 <a href='#codec' id='QQ2-1-4'>Codec</a></span>
<br />     <span class='subsectionToc'>1.2 <a href='#a-block-diagram-of-the-step-codec' id='QQ2-1-6'>A block diagram of the step codec</a></span>
<br />    <span class='sectionToc'>2 <a href='#the-gop-group-of-pictures-concept' id='QQ2-1-8'>The GOP (Group Of Pictures) concept</a></span>
<br />    <span class='sectionToc'>3 <a href='#hybrid-coding-alternatives' id='QQ2-1-10'>Hybrid coding alternatives</a></span>
<br />    <span class='sectionToc'>4 <a href='#deblocking-filtering' id='QQ2-1-12'>Deblocking filtering</a></span>
<br />    <span class='sectionToc'>5 <a href='#bitrate-allocation' id='QQ2-1-14'>Bit-rate allocation</a></span>
<br />    <span class='sectionToc'>6 <a href='#coding-in-the-transform-domain' id='QQ2-1-17'>Coding in the Transform Domain</a></span>
<br />     <span class='subsectionToc'>6.1 <a href='#the-ipp-decorrelation-pattern' id='QQ2-1-18'>The IPP... decorrelation pattern</a></span>
<br />     <span class='subsectionToc'>6.2 <a href='#a-block-diagram-of-the-step-codec1' id='QQ2-1-19'>A block diagram of the step codec</a></span>
<br />     <span class='subsectionToc'>6.3 <a href='#spatial-multiresolution' id='QQ2-1-21'>Spatial multiresolution</a></span>
<br />     <span class='subsectionToc'>6.4 <a href='#sq-layers-progression-next-milestone' id='QQ2-1-24'>SQ (layers) progression (next milestone?)</a></span>
<br />    <span class='sectionToc'>7 <a href='#references' id='QQ2-1-25'>References</a></span>
   </div>
<!-- l. 6 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='hybrid-video-coding'><span class='titlemark'>1   </span> <a id='x1-20001'></a>Hybrid video coding</h3>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 10 --><p class='noindent' id='-hybrid-video-coding-'><div style='text-align:center;'> <img src='graphics/hybrid_coding.svg' /> </div>  <a id='x1-2001r1'></a>
<a id='x1-2002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 1: </span><span class='content'>Hybrid video coding.
</span></figcaption><!-- tex4ht:label?: x1-2001r1  -->
                                                                  

                                                                  
   </figure>
<!-- l. 15 --><p class='indent'>   See the Fig. <a href='#x1-2001r1'>1<!-- tex4ht:ref: fig:hybrid_coding  --></a>.
</p>
     <ul class='itemize1'>
     <li class='itemize'>Used in all the video compression standards.
     </li>
     <li class='itemize'>Intracoded images are transformed (\(T\)) and quantized (\(Q\)).
     </li>
     <li class='itemize'>Intercoded images are also motion compensated (\(P\)).
     </li>
     <li class='itemize'>The encoder incorporates a decoder to avoid the drift error.</li></ul>
   <h4 class='subsectionHead' id='codec'><span class='titlemark'>1.1   </span> <a id='x1-30001.1'></a>Codec</h4>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 34 --><p class='noindent' id='-a-interintra-video-codec-'><div style='text-align:center;'> <img src='graphics/codec.svg' /> </div>  <a id='x1-3001r2'></a>
<a id='x1-3002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 2: </span><span class='content'>A inter/intra video codec.                                    </span></figcaption><!-- tex4ht:label?: x1-3001r1  -->
                                                                  

                                                                  
   </figure>
<!-- l. 39 --><p class='indent'>   The Figure <a href='#x1-4001r3'>3<!-- tex4ht:ref: fig:IPP_codec  --></a> describes an inter/intra video codec, that corresponds
to:
</p><!-- l. 45 --><p class='indent'>   \begin {equation}  {\mathbf W}_k = \text {color-T}({\mathbf V}_k), \tag {a}  \end {equation}

</p><!-- l. 50 --><p class='indent'>   \begin {equation}  {\mathbf W}_{k-1} = Z^{-1}({\mathbf W}, k-1), \tag {b}  \end {equation}
and by definition, \(Z^{-1}({\mathbf W}, -1) = {\mathbf 0}\),
</p><!-- l. 56 --><p class='indent'>   \begin {equation}  \overset {(k-1)\rightarrow k}{\mathbf M} = \text {ME}({\mathbf W}_{k-1}, {\mathbf W}_k), \tag {c}  \end {equation}
where ME stands for Motion Estimation, and by definition, \(\overset {(-1)\rightarrow 0}{{\mathbf M}} = {\mathbf 0}\),
</p><!-- l. 63 --><p class='indent'>   \begin {equation}  \overset {(k-1)\rightarrow k}{\mathbf M} = \overset {(k-1)\rightarrow k}{\mathbf M} \text {(lossless~coding)}, \tag {d}  \end {equation}

</p><!-- l. 68 --><p class='indent'>   \begin {equation}  \overset {(k-1)\rightarrow k}{\mathbf M} = \overset {(k-1)\rightarrow k}{\mathbf M} \text {(lossless~decoding)}, \tag {e}  \end {equation}

</p><!-- l. 73 --><p class='indent'>   \begin {equation}  {\mathbf E}_k = {\mathbf W}_k - \overset {\wedge }{{\mathbf W}}_k, \tag {f}  \end {equation}
where the symbol \(-\) represents to the pixel-wise substraction,
</p><!-- l. 79 --><p class='indent'>   \begin {equation}  \overset {\sim }{{\mathbf E}_k} = \text {QE}({\mathbf E}_k), \tag {g}  \end {equation}
where QE\((\cdot )\) represents the lossy compression of the prediction error texture
data,
</p><!-- l. 86 --><p class='indent'>   \begin {equation}  \overset {\sim }{\mathbf E}_k = \text {DQ}^{-1}(\overset {\sim }{\mathbf E}_k), \tag {h}  \end {equation}
where DQ\(^{-1}(\cdot )\) represents the decompression of the prediction error texture data,
</p><!-- l. 93 --><p class='indent'>   \begin {equation}  \overset {\sim }{\mathbf W}_k \leftarrow \overset {\sim }{\mathbf E}_k + \overset {\wedge }{\mathbf W}_k, \tag {i}  \end {equation}
and notice that if \(\overset {\wedge }{\mathbf W}_k = {\mathbf 0}\), then \(\overset {\sim }{\mathbf E}_k = \overset {\sim }{\mathbf W}_k\),
</p><!-- l. 100 --><p class='indent'>   \begin {equation}  \overset {\wedge }{\mathbf W}_k = \text {P}(\overset {\sim }{\mathbf W}_{k-1}, \overset {(k-1)\rightarrow k}{\mathbf M}), \tag {j}  \end {equation}
where P\((\cdot ,\cdot )\) is a motion compensated predictor, and
</p><!-- l. 106 --><p class='indent'>   \begin {equation}  \overset {\wedge }{\mathbf W}_{k-1} = Z^{-1}(\overset {\wedge }{\mathbf W}, k-1), \tag {k}  \end {equation}
where by definition, \(Z^{-1}(\overset {\wedge }{\mathbf W}, -1) = 0\), and
</p><!-- l. 112 --><p class='indent'>   \begin {equation}  {\mathbf V} = \text {color-T}^{-1}({\mathbf W}_k), \tag {l}  \end {equation}
is the inverse color transform.
</p><!-- l. 115 --><p class='indent'>   Notice that if \(\overset {\wedge }{{\mathbf W}}_k\) is similar to \({\mathbf W}_k\), then \({\mathbf E}_k\) will be approximately zero, and therefore,
easely compressed. Another interesting aspect to highlight is that the encoder
replicates de decoder in order to use the reconstructed images as reference and avoid
the drift error.
</p>
   <h4 class='subsectionHead' id='a-block-diagram-of-the-step-codec'><span class='titlemark'>1.2   </span> <a id='x1-40001.2'></a>A block diagram of the step codec</h4>
<!-- l. 123 --><p class='noindent'>It’s time to test the performance of the ME/MC process previously described, in the
image domain. We encode a sequence of frames \(\{W_k\}\) using the pattern IPP... which means
that the first frame will be intra-coded (I-type frame) and the rest of frames of the
GOF (Group Of (<a href='https://en.wikipedia.org/wiki/Group_of_pictures'>Frames</a>) will be predicted-coded (P-type frame), respect to the
previous one.
</p>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 133 --><p class='noindent' id='-a-simple-ipp-image-codec-'><div style='text-align:center;'> <img src='graphics/codec2.svg' /> </div>  <a id='x1-4001r3'></a>
<a id='x1-4002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 3: </span><span class='content'>A simple IPP... image codec.                                 </span></figcaption><!-- tex4ht:label?: x1-4001r1  -->
                                                                  

                                                                  
   </figure>
<!-- l. 138 --><p class='indent'>   The IPP... coding can be done by the codec shown in the Fig. <a href='#x1-4001r3'>3<!-- tex4ht:ref: fig:IPP_codec  --></a>, where:
</p><!-- l. 154 --><p class='indent'>   \begin {equation}  V_k \leftarrow \text {C}(W_k) = \begin {bmatrix} \frac {1}{4} &amp; \frac {1}{2} &amp; \frac {1}{4} \\ \frac {1}{2} &amp; 0 &amp; -\frac {1}{2} \\ -\frac {1}{4} &amp; \frac {1}{2} &amp; -\frac {1}{4} \end {bmatrix} \begin {bmatrix} W_k.\text {R} \\ W_k.\text {G} \\ W_k.\text {B} \end {bmatrix} , \tag {a}  \end {equation}

</p><!-- l. 159 --><p class='indent'>   \begin {equation}  Z^{-1}(V_k) = V_{k-1}, \tag {b}  \end {equation}
and by definition, \(Z^{-1}(V_{-1}) = 0\),
</p><!-- l. 165 --><p class='indent'>   \begin {equation}  \overset {k\rightarrow k-1}{V} \leftarrow \text {M}(V_k, V_{k-1}), \tag {c}  \end {equation}
where M stands for Motion Estimation, and by definition, \(\overset {0\rightarrow (-1)}{V}=0\),
</p><!-- l. 172 --><p class='indent'>   \begin {equation}  \overset {\sim }{\overset {k\rightarrow k-1}{V}} \leftarrow \text {E}_{\overset {\rightarrow }{V}}(\overset {k\rightarrow k-1}{V}), \tag {d}  \end {equation}
where E\(_{\overset {\rightarrow }{V}}(\cdot )\) represents the lossy compression of the motion data,
</p><!-- l. 179 --><p class='indent'>   \begin {equation}  \overset {\sim }{\overset {k\rightarrow k-1}{V}} \leftarrow \text {D}_{\overset {\rightarrow }{V}}(\overset {\sim }{\overset {k\rightarrow k-1}{V}}), \tag {e}  \end {equation}
where D\(_{\overset {\rightarrow }{V}}(\cdot )\) represents the decompression of the motion data,
</p><!-- l. 186 --><p class='indent'>   \begin {equation}  E_k \leftarrow V_k - \overset {\wedge }{{V}}_k, \tag {f}  \end {equation}
where the symbol \(-\) represents to the pixel-wise substraction,
</p><!-- l. 192 --><p class='indent'>   \begin {equation}  \overset {\sim }{E_k} \leftarrow \text {E}_{E}(E_k), \tag {g}  \end {equation}
where E\(_{E}(\cdot )\) represents the lossy compression of the prediction error texture
data,
</p><!-- l. 199 --><p class='indent'>   \begin {equation}  \overset {\sim }{E}_k \leftarrow \text {D}_{E}(\overset {\sim }{E}_k), \tag {h}  \end {equation}
where D\(_{E}(\cdot )\) represents the decompression of the prediction error texture data,
</p><!-- l. 206 --><p class='indent'>   \begin {equation}  \overset {\sim }{V}_k \leftarrow \overset {\sim }{E}_k + \overset {\wedge }{V}_k, \tag {i}  \end {equation}
and notice that if \(\overset {\wedge }{V}_k=0\), then \(\overset {\sim }{E}_k = \overset {\sim }{V}_k\),
</p><!-- l. 213 --><p class='indent'>   \begin {equation}  \overset {\wedge }{V}_k \leftarrow \text {P}(\overset {\sim }{\overset {k\rightarrow k-1}{V}}, \overset {\sim }{V}_{k-1}), \tag {j}  \end {equation}
where P\((\cdot ,\cdot )\) is a motion compensated predictor.
</p><!-- l. 216 --><p class='indent'>   Notice that if \(\overset {\wedge }{{V}}_k\) is similar to \(V_k\), then \(E_k\) will be approximately zero, and therefore,
easely compressed. Another interesting aspect to highlight is that the encoder
replicates de decoder in order to use the reconstructed images as reference and avoid
the drift error.
</p>
   <h3 class='sectionHead' id='the-gop-group-of-pictures-concept'><span class='titlemark'>2   </span> <a id='x1-50002'></a>The GOP (Group Of Pictures) concept</h3>
     <ul class='itemize1'>
     <li class='itemize'>The temporal redundancy is exploited by blocks of images called GOPs.
     This means that a GOP can be decoded independently of the rest of GOPs
     (see the Fig. <a href='#x1-5001r4'>4<!-- tex4ht:ref: fig:GOPs  --></a>).</li></ul>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 232 --><p class='noindent' id='-a-gop-'><div style='text-align:center;'> <img src='graphics/GOPs.svg' /> </div>  <a id='x1-5001r4'></a>
<a id='x1-5002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 4: </span><span class='content'>A GOP.
</span></figcaption><!-- tex4ht:label?: x1-5001r2  -->
                                                                  

                                                                  
   </figure>
   <h3 class='sectionHead' id='hybrid-coding-alternatives'><span class='titlemark'>3   </span> <a id='x1-60003'></a>Hybrid coding alternatives</h3>
     <ul class='itemize1'>
     <li class='itemize'><span class='ecbx-1000'>t+2d</span>: The sequence of images is decorrelated first along the time (t) and
     the residue images are compressed, exploiting the remaining spatial (2d)
     redundancy. Examples: MPEG* and H.26* codecs (except H.264/SVC).
     </li>
     <li class='itemize'><span class='ecbx-1000'>2d+t</span>: The spatial (2d) redudancy is explited first (using typically the
     DWT) and after that, the coefficients are decorrelated along the time (t).
     For now, this has only been an experimental setup because most DWT
     transformed domains are not invariant to the displacement, and therefore,
     ME/MC can not be directly applied.
     </li>
     <li class='itemize'><span class='ecbx-1000'>2d+t+2d</span>:  The  fist  step  creates  a  Laplacian  Pyramid  (2d),  which
     is  invariant  to  the  displacement.  Next,  each  level  of  the  pyramid
     is  decorrelated  along  the  time  (t)  and  finally,  the  remaining  spatial
     redundancy is removed (2d). The Fig <a href='#x1-6001r5'>5<!-- tex4ht:ref: fig:H264-S-SVC  --></a> show an example for H.264/SVC.</li></ul>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 259 --><p class='noindent' id='-svc-scheme-in-h-'><div style='text-align:center;'> <img src='graphics/H264-S-SVC.svg' /> </div>  <a id='x1-6001r5'></a>
<a id='x1-6002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 5: </span><span class='content'>SVC scheme in H.264.
</span></figcaption><!-- tex4ht:label?: x1-6001r3  -->
                                                                  

                                                                  
   </figure>
   <h3 class='sectionHead' id='deblocking-filtering'><span class='titlemark'>4   </span> <a id='x1-70004'></a>Deblocking filtering</h3>
     <ul class='itemize1'>
     <li class='itemize'>If   any   other   block-overlaping   techniques   have   not   been   applied,
     block-based video encoders improve their performance if a deblocking filter
     in used to create the quantized prediction predictions (see the Fig. <a href='#x1-7001r6'>6<!-- tex4ht:ref: fig:350px-Deblock1  --></a>).</li></ul>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 275 --><p class='noindent' id='-deblocking-filetering-effect-'><div style='text-align:center;'> <img src='graphics/350px-Deblock1.jpg' /> </div>  800 <a id='x1-7001r6'></a>
<a id='x1-7002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 6: </span><span class='content'>Deblocking filetering effect.
</span></figcaption><!-- tex4ht:label?: x1-7001r4  -->
                                                                  

                                                                  
   </figure>
     <ul class='itemize1'>
     <li class='itemize'>The low-pass filter is applied only on the block boundaries.</li></ul>
   <h3 class='sectionHead' id='bitrate-allocation'><span class='titlemark'>5   </span> <a id='x1-80005'></a>Bit-rate allocation</h3>
     <ul class='itemize1'>
     <li class='itemize'>
     <!-- l. 289 --><p class='noindent'>VBR: Under a constant quantization level (constant video quality), the
     number of bits that each compressed image needs depends on the image
     content (Variable Bit-Rate). In the Fig. <a href='#x1-8001r7'>7<!-- tex4ht:ref: fig:closed-loop-1_ir  --></a> there is an example. </p><figure class='figure' id='-example-of-variable-bitallocation-'> 
<div style='text-align:center;'> <img src='graphics/closed-loop-1_ir.svg' /> </div>   <a id='x1-8001r7'></a>
<a id='x1-8002'></a>
<figcaption class='caption'><span class='id'>Figure 7: </span><span class='content'>Example of variable bit-allocation.
</span></figcaption><!-- tex4ht:label?: x1-8001r5  -->
     </figure>
     </li>
     <li class='itemize'>
     <!-- l. 301 --><p class='noindent'>CBR: Using a Constant Bit-Rate strategy, all frames need the same space.
     In the Fig. <span class='ecbx-1000'>??</span> there is an example. </p><figure class='figure' id='-example-of-constant-bitallocation-'> 
<div style='text-align:center;'> <img src='graphics/CBR.svg' /> </div>   <a id='x1-8003r8'></a>
<a id='x1-8004'></a>
<figcaption class='caption'><span class='id'>Figure 8: </span><span class='content'>Example of constant bit-allocation.
</span></figcaption><!-- tex4ht:label?: x1-8003r5  -->
     </figure>
     </li></ul>
<!-- l. 312 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='coding-in-the-transform-domain'><span class='titlemark'>6   </span> <a id='x1-90006'></a>Coding in the Transform Domain</h3>
<!-- l. 314 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='the-ipp-decorrelation-pattern'><span class='titlemark'>6.1   </span> <a id='x1-100006.1'></a>The IPP... decorrelation pattern</h4>
                                                                  

                                                                  
<!-- l. 315 --><p class='noindent'>It’s time to put together all the “tools” that we have developed for encoding a
sequence of frames \(\{V_k\}\). First, the sequence will be splitted into GOFs (<a href='https://en.wikipedia.org/wiki/Group_of_pictures'>Group Of
Frames</a>), and the structure of each GOF will be IPP... <span class='cite'>[<a href='#Xle1991mpeg'>1</a>]</span>, which means that
the first frame of each GOF will be intra-coded (I-type), and the rest of
frames of the GOF will be predicted-coded (P-type), respect to the previous
one<span class='footnote-mark'><a href='#fn1x0' id='fn1x0-bk'><sup class='textsuperscript'>1</sup></a></span><a id='x1-10001f1'></a>.
Notice that in an I-type frame all the coefficients (<span class='ecti-1000'>coeffs </span>in short, remember that we
are compensating the motion in the DWT domain) will be I-type coeffs, and in a
P-type frame, the different coeffs will be I-type or P-type.
</p><!-- l. 329 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='a-block-diagram-of-the-step-codec1'><span class='titlemark'>6.2   </span> <a id='x1-110006.2'></a>A block diagram of the step codec</h4>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 333 --><p class='noindent' id='-the-ipp-mrvc-step-codec-notice-that-the-input-to-the-step-encoder-is-a-dwt-transformed-sequence-of-frames-'><div style='text-align:center;'> <img src='graphics/codec4.svg' /> </div>  <a id='x1-11001r9'></a>
<a id='x1-11002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 9: </span><span class='content'>The IPP... MRVC step codec. Notice that the input to the (step)
encoder is a DWT transformed sequence of frames.                       </span></figcaption><!-- tex4ht:label?: x1-11001r6  -->
                                                                  

                                                                  
   </figure>
<!-- l. 339 --><p class='indent'>   The MRVC IPP... step (one resolution level) codec has been described in the
Fig. <a href='#x1-11001r9'>9<!-- tex4ht:ref: fig:codec  --></a>. The equations that describe this system are:
</p><!-- l. 345 --><p class='indent'>   \begin {equation}  (V_k.L, V_k.H) \leftarrow \text {DWT}(V_k), \tag {a}  \end {equation}
where \(\leftarrow \) denotes the <a href='https://en.wikipedia.org/wiki/Assignment_(computer_science)'>assignment</a> operator, and \(V_k\) is the \(k\)-th frame of the sequence,
</p><!-- l. 353 --><p class='indent'>   \begin {equation}  [V_k.L] \leftarrow \text {DWT}^{-1}(V_k.L, 0), \tag {E.a}  \end {equation}

</p><!-- l. 358 --><p class='indent'>   \begin {equation}  Z^{-1}([V_k.L]) = [V_{k-1}.L], \tag {E.b}  \end {equation}
and by definition, \(Z^{-1}([V_{-1}.L]) = 0\),
</p><!-- l. 364 --><p class='indent'>   \begin {equation}  \overset {k\rightarrow k-1}{V} \leftarrow \text {M}([V_k.L], [V_{k-1}.L]), \tag {E.c}  \end {equation}
where M stands for Motion estimation, and by definition, \(\overset {0\rightarrow (-1)}{V}=0\),
</p><!-- l. 371 --><p class='indent'>   \begin {equation}  [\hat {V}_k.L] \leftarrow \text {P}(\overset {k\rightarrow k-1}{V}, [V_{k-1}.L]), \tag {E.d}  \end {equation}
where P stands for motion compensated Prediction,
</p><!-- l. 377 --><p class='indent'>   \begin {equation}  [E_k.L] \leftarrow [V_k.L] - [\hat {V}_k.L], \tag {E.e}  \end {equation}

</p><!-- l. 382 --><p class='indent'>   \begin {equation}  \{[M_k],[S_k]\} \leftarrow \text {EW-min}([V_k.L], [E_k.L]) \tag {E.f}  \end {equation}
where \begin {equation}  [M_k]_{i,j}=\text {min}([V_k.L]_{i,j}, [E_k.L]_{i,j}),  \end {equation}
and \([S_k]\) is a binary matrix defined by \begin {equation}  [S_k]_{i,j} = \left \{ \begin {array}{lll} 0 &amp; \text {if}~[V_k.L]_{i,j} &lt; [E_k.L]_{i,j} &amp; \text {(I-type coeff)} \\ 1 &amp; \text {otherwise} &amp; \text {(P-type coeff)}, \end {array} \right . \label {eq:matrix}  \end {equation}
(notice that \([M_k]\), that contains the element-wise minimum of both matrices, is
discarded)
</p><!-- l. 403 --><p class='indent'>   \begin {equation}  [V_k.H] \leftarrow \text {DWT}^{-1}(0, V_k.H), \tag {b}  \end {equation}

</p><!-- l. 408 --><p class='indent'>   \begin {equation}  [E_k.H] \leftarrow [V_k.H] - [\hat {V}_k.H], \tag {c}  \end {equation}
where, notice that \begin {equation}  [E_k.H]_{i,j} = \left \{ \begin {array}{ll} {[}V_k.H{]}_{i,j} &amp; \text {if}~{[}\hat {V}'_k.H{]}_{i,j} = 0~\text {(I-type coeff)} \\ {[}V_k.H{]}_{i,j} - [\hat {V}'_k.H]_{i,j} &amp; \text {otherwise}~\text {(P-type coeff)}, \end {array} \right .  \end {equation}

</p><!-- l. 422 --><p class='indent'>   \begin {equation}  [\tilde {E}_k.H] \leftarrow \text {Q}([E_K.H]), \tag {d}  \end {equation}

</p><!-- l. 427 --><p class='indent'>   \begin {equation}  [\tilde {E}_k.H] \leftarrow \text {Q}^{-1}([\tilde {E}_K.H]), \tag {E.g}  \end {equation}

</p><!-- l. 432 --><p class='indent'>   \begin {equation}  [\tilde {V}_k.H] \leftarrow [\tilde {E}_k.H] + [\hat {V}'_k.H], \tag {E.h}  \end {equation}
and notice that if \([\hat {V}_k.H]=0\), then \([\tilde {V}_k.H] = [\tilde {E}_k.H]\),
</p><!-- l. 439 --><p class='indent'>   \begin {equation}  Z^{-1}([\tilde {V}_k.H]) = [V_{k-1}.H], \tag {E.i}  \end {equation}
and by definition, \(Z^{-1}([V_{-1}.H]) = 0\),
</p><!-- l. 445 --><p class='indent'>   \begin {equation}  [\hat {V}_k.H] \leftarrow \text {P}(\overset {k\rightarrow k-1}{V}, [\overset {\sim }{V}_{k-1}.H]), \tag {E.j}  \end {equation}

</p><!-- l. 455 --><p class='indent'>   \begin {equation}  [\hat {V}'_k.H]_{i,j} \leftarrow \left \{ \begin {array}{ll} {[}\hat {V}_k.H{]}_{i,j} &amp; \text {if}~{[}E_k.L{]}_{i,j} &lt; {[}V_k.L{]}_{i,j} \text {(P-type coeff)} \\ 0 &amp; \text {otherwise (I-type coeff)}, \end {array} \right . \tag {E.k}  \end {equation}

</p><!-- l. 460 --><p class='indent'>   \begin {equation}  (0, \tilde {E}_k.H) \leftarrow \text {DWT}([\tilde {E}_k.H]), \tag {f}  \end {equation}

</p><!-- l. 465 --><p class='indent'>   \begin {equation}  \{V_k.L, \tilde {E}_k.H\} \leftarrow \text {E}(V_k.L, \tilde {E}_k.H), \tag {g}  \end {equation}
where E represents the entropy coding of both data sources, in two different
code-streams,
</p><!-- l. 472 --><p class='indent'>   \begin {equation}  (V_k.L, \tilde {E}_k.H) \leftarrow \text {E}^{-1}(\{V_k.L, \tilde {E}_k.H\}), \tag {h}  \end {equation}

</p><!-- l. 477 --><p class='indent'>   \begin {equation}  [\tilde {E}_k.H] \leftarrow \text {DWT}^{-1}(0, \tilde {E}_k.H), \tag {i}  \end {equation}

                                                                  

                                                                  
</p><!-- l. 482 --><p class='indent'>   \begin {equation}  (0, \tilde {V}_k.H) \leftarrow \text {DWT}(0, [\tilde {V}_k.H]), \tag {j}  \end {equation}
</p><!-- l. 484 --><p class='indent'>   and
</p><!-- l. 489 --><p class='indent'>   \begin {equation}  \tilde {V}_k \leftarrow \text {DWT}^{-1}(V_k.L, \tilde {V}_k.H). \tag {k}  \end {equation}
</p><!-- l. 491 --><p class='indent'>   The IPP... codec is inspired in Differential Pulse Code Moldulation. This
<a href='https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/12-IPP_coding/DPCM.ipynb'>notebook</a> shows how to implement a simple DPCM codec.
</p>
   <h4 class='subsectionHead' id='spatial-multiresolution'><span class='titlemark'>6.3   </span> <a id='x1-120006.3'></a>Spatial multiresolution</h4>
<!-- l. 497 --><p class='noindent'>As it can be seen in the previous section, in each IPP... iteration of the step encoder,
only the high-frequency information of the sequence of frames is decorrelated (\(H\)
subbands) considering the information provided by the low-frequences (\(L\) subband),
which are losslessly transmitted between the encoder and the decoder. Notice also
that if the \(L\) data cannot be transmitted to the decoder, a drift error will occur
because the matrix \(S_k\) will be different in the encoder and the decoder for the same
frame \(k\).
</p><!-- l. 506 --><p class='indent'>   Obviously (and unfortunately), the lossless transmission of the \(L\)’s bounds the
compression ratio that we will get. One solution is to perform more (than 1) levels at
the DWT stage (see Eq. (a)) and to apply the IPP... MRVC step encoder by spatial
resolutions, starting at the lowest, as the decoder will do at decompression time. If we
represent the Spatial Resolution Level (SRL) with an superindex, being 0 the original
SRL, we can express the operation of the codec described in the Fig. <a href='#x1-11001r9'>9<!-- tex4ht:ref: fig:codec  --></a> by
\begin {equation}  \left \{ \begin {array}{l} \text {SE}(V^0_k) = \{V^0_k.L, \tilde {E}^0_k.H\} = \{V^1_k, \tilde {E}^0_k.H\} \\ \text {SD}(\{V^1_k, \tilde {E}^0_k.H\}) = \tilde {V}^0_k, \end {array} \right . \label {eq:codec_1l}  \end {equation}
where \(\text {SE}(\cdot )\) represents to the operation of the IPP... step encoder and \(\text {SD}(\cdot )\) to the operation of
the IPP... step decoder. As it can be seen, Eq. <span class='ecbx-1000'>??</span> is only valid when only one level of
the DWT has been applied.
</p><!-- l. 528 --><p class='indent'>   In general, for \(s\) levels of the DWT, we have that \begin {equation}  \left \{ \begin {array}{l} \text {SE}(V^{s-1}_k) = \{V^s_k, \tilde {E}^{s-1}_k.H\} \\ \text {SD}(\{V^s_k, \tilde {E}^{s-1}_k.H\}) = \tilde {V}^{s-1}_k, \end {array} \right . \label {eq:codec_sl}  \end {equation}
where \(\tilde {V}^{s-1}\) is the \((s-1)\)-th SRL of the reconstructed sequence \(\tilde {V}\).
</p><!-- l. 541 --><p class='indent'>   The next SRL (\(s-2\)), \(\tilde {V}^{s-2}\), is determined by \begin {equation}  \left \{ \begin {array}{l} \text {SE}(\tilde {V}^{s-2}_k) = \{\tilde {V}^{s-1}_k, \tilde {E}^{s-2}_k.H\} \\ \text {SD}(\{\tilde {V}^{s-1}_k, \tilde {E}^{s-2}_k.H\}) = \tilde {V}^{s-2}_k, \end {array} \right . \label {eq:codec_s1l}  \end {equation}
and finally, for the highest SRL, we get \(\tilde {V}^0\) defined by Eq. <span class='ecbx-1000'>??</span>.
</p>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 565 --><p class='noindent' id='-the-ipp-mrvc-encoder-'><div style='text-align:center;'> <img src='graphics/encoder.svg' /> </div>  <a id='x1-12001r10'></a>
<a id='x1-12002'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 10: </span><span class='content'>The IPP... MRVC encoder.                                  </span></figcaption><!-- tex4ht:label?: x1-12001r6  -->
                                                                  

                                                                  
   </figure>
<!-- l. 570 --><p class='indent'>   So, only the lowest SRL of \(\tilde {V}\), \(\tilde {V}^s\) is an III... pure sequence of small frames, losslessly
encoded. This multiresolution (multistage) scheme has been described in the Fig. <a href='#x1-12001r10'>10<!-- tex4ht:ref: fig:encoder  --></a>.
The output of an IPP... encoder will be refered as “spatial-layers”, or simply as
“S-layers”.
</p><!-- l. 576 --><p class='indent'>   The Fig. <a href='#x1-12003r11'>11<!-- tex4ht:ref: fig:decoder  --></a> shows the decoder. It inputs the collection of subbands generated by
the encoder and for each one, a video with a different spatial resolution is
obtained.
</p>
   <figure class='figure'> 

                                                                  

                                                                  
                                                                  

                                                                  
<!-- l. 582 --><p class='noindent' id='-the-ipp-mrvc-decoder-'><div style='text-align:center;'> <img src='graphics/decoder.svg' /> </div>  <a id='x1-12003r11'></a>
<a id='x1-12004'></a>
</p>
<figcaption class='caption'><span class='id'>Figure 11: </span><span class='content'>The IPP... MRVC decoder.                                  </span></figcaption><!-- tex4ht:label?: x1-12003r6  -->
                                                                  

                                                                  
   </figure>
   <h4 class='subsectionHead' id='sq-layers-progression-next-milestone'><span class='titlemark'>6.4   </span> <a id='x1-130006.4'></a>SQ (layers) progression (next milestone?)</h4>
<!-- l. 588 --><p class='noindent'>The logical order of the S-layers in the code-stream is the one that allows, when the
code-stream is decoded sequentially, the progressive increase of the spatial resolution
of the video. For example, if \(s\) is the number of levels of the DWT, the generated
code-stream has \((s+1)\) S-layers \begin {equation*}  \{V^s,\tilde {E}^{s-1}.H,\tilde {E}^{s-2}.H,\cdots ,\tilde {E}^0.H\},  \end {equation*}
which are able to generate \((s+1)\) progressive reconstructions \begin {equation*}  \{V^s,\tilde {V}^{s-1},\tilde {V}^{s-2},\cdots ,\tilde {V}^0\}.  \end {equation*}
</p><!-- l. 602 --><p class='indent'>   Moreover, Quality (Q-progression) scalability in each SRL can be also achieved in
the high-frequency textures if a quality-scalable image codec such as JPEG2000 <span class='cite'>[<a href='#Xtaubman2002jpeg2000'>2</a>]</span>
replaces the PNG compressor, generating a number \(q\) of quality-layers (“Q-layers”) by
each motion compensated high-frequency subband. A SQ-progression is defined
considering both forms of scalability (spatial and quality), with a higher number of
layers. For example, if \(s=3\) (2 IPP...-type iterations) and \(q=2\), the progression of layers would
be \begin {equation*}  \{V^s[1],V^s[0],\tilde {E}^{s-1}.H[1],\tilde {E}^{s-1}.H[0],\tilde {E}^{s-2}.H[1],\tilde {E}^{s-2}.H[0],\cdots ,\tilde {E}^0.H[1],\tilde {E}^0.H[0]\}.  \end {equation*}
</p><!-- l. 634 --><p class='indent'>   The use of quality scalability boosts the possibilities in real-time streaming scenarios
where the transmission bit-rate can be variable (sending more or less Q-layers of a given
spatial resolution depending on the bit-rate). Notice that the SQ-progression is free of
drift-error.<span class='footnote-mark'><a href='#fn2x0' id='fn2x0-bk'><sup class='textsuperscript'>2</sup></a></span><a id='x1-13001f2'></a>
</p><!-- l. 652 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='references'><span class='titlemark'>7   </span> <a id='x1-140007'></a>References</h3>
   <div class='thebibliography'>
   <p class='bibitem'><span class='biblabel'>
 [1]<span class='bibsp'>   </span></span><a id='Xle1991mpeg'></a>D. Le Gall.   <a href='https://dl.acm.org/doi/pdf/10.1145/103085.103090'>MPEG: A Video Compression Standard for Multimedia
   Applications</a>. <span class='ecti-1000'>Communications of the ACM</span>, 34(4):46–58, 1991.
   </p>
   <p class='bibitem'><span class='biblabel'>
 [2]<span class='bibsp'>   </span></span><a id='Xtaubman2002jpeg2000'></a>D.S. Taubman and W.M. Marcellin.   <a href='https://last.hit.bme.hu/download/firtha/video/JPEG2000/David%20S.%20Taubman,%20%20Michael%20W.%20Marcellin%20%20(auth.)%20JPEG2000%20Image%20Compression%20Fundamentals,%20Standards%20and%20Practice%20%202002.pdf'><span class='ecti-1000'>JPEG2000. Image Compression
   </span><span class='ecti-1000'>Fundamentals, Standards and Practice</span></a>. Kluwer Academic Publishers, 2002.
</p>
   </div>
   <div class='footnotes'><!-- l. 324 --><p class='indent'>     <span class='footnote-mark'><a href='#fn1x0-bk' id='fn1x0'><sup class='textsuperscript'>1</sup></a></span><span class='ecrm-0800'>A P-type frame except for the second one, that always has a I-frame as reference.</span></p>
<!-- l. 641 --><p class='indent'>     <span class='footnote-mark'><a href='#fn2x0-bk' id='fn2x0'><sup class='textsuperscript'>2</sup></a></span><span class='ecrm-0800'>Other progressions such as the QS-progression should generate drift because the decoder at
</span><span class='ecrm-0800'>some truncation points of the code-stream would use a low-frequency information with a different
</span><span class='ecrm-0800'>quality than the encoderd used.</span></p>                                                                                </div>
 
</body> 
</html>